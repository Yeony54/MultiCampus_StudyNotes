Machine learning

# Pandas Data Preprocessing

ë°ì´í„° ë¶„ì„, machine learning, deep learningì„ í•  ë•Œì—ëŠ” ë°ì´í„°ì˜ì–‘, í’ˆì§ˆì´ ì¤‘ìš”í•˜ë‹¤.



### 01. ë°ì´í„° ì „ì²˜ë¦¬ ì¢…ë¥˜

- missing value (ê²°ì¸¡ì¹˜)
- Outline (ì´ìƒì¹˜)
- ì¤‘ë³µë°ì´í„°
- Dataì˜ ë‹¨ìœ„ì²˜ë¦¬
- ì •ê·œí™”



### 02. Missing Value

- **Missing Value**(ê²°ì¹˜ê°’)ì´ë€? DataFrameì•ˆì— ëˆ„ë½ëœ ê°’ì„ ì˜ë¯¸í•œë‹¤.
  <small>ë°ì´í„° ì…ë ¥ì‹œ ì‹¤ìˆ˜ë¡œ ëˆ„ë½ëœ ê°’ì´ë‚˜, íŒŒì¼ ë³€í™˜ ì‹œ ì²˜ë¦¬ ë¬¸ì œë¡œ ëˆ„ë½ëœ ê²ƒì´ ì˜ˆì´ë‹¤.</small>
- ëˆ„ë½ëœ ê°’ì€ `NaN`ìœ¼ë¡œ í‘œì‹œëœë‹¤.
- Missing Valueë¥¼ ì²˜ë¦¬í•˜ëŠ” ë°©ë²•ì—ëŠ” ì‚­ì œ, ëŒ€ì²´ë“±ì˜ ë°©ë²•ì´ ìˆë‹¤.

ë°ì´í„°ë¥¼ ê°€ì§€ê³  ì²˜ìŒí•´ì•¼í•˜ëŠ”ê²ƒì€ Missing Valueê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ëŠ” ì¼ì´ë‹¤.

ê²°ì¹˜ê°’ì´ ë§ìœ¼ë©´ ê³„ì‚°í•˜ëŠ”ë° ì¢‹ì§€ì•Šì€ ì˜í–¥ì„ ì£¼ê¸° ë•Œë¬¸ì—, ì´ë¥¼ ì²˜ë¦¬í•´ì„œ `NaN`ì´ ì—†ëŠ” ë°ì´í„°ë¥¼ ë¨¼ì € ë§Œë“¤ì–´ì•¼ í•œë‹¤.



#### A. NaNê°’ ì°¾ëŠ” ë°©ë²•

NaNê°’ ì°¾ëŠ”ë°©ë²•ì€ ì—¬ëŸ¬ê°€ì§€ê°€ ìˆë‹¤.

- df.info()

  infoë¥¼ í†µí•´ `NaN` ì œì™¸ í†µê³„ëœ ê°’ì„ ë³´ê³  ë°ì´í„°ê°€ ì–¼ë§ˆë‚˜ ì •ëˆë˜ì—ˆëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

- value_counts()

  ```python
  df['deck'].value_counts(dropna=False)
  ```

  value_countì˜ ì†ì„± `dropna`ë¥¼ Falseë¡œ í•˜ì—¬ NaNê°’ì„ ê°™ì´ ì„¸ì–´ì¤„ ìˆ˜ ìˆë‹¤.

- isnull()

  ```python
  df.isnull().sum(axis=0)
  ```

  isnullì„ ì‚¬ìš©í•´ `NaN`ê°’ì˜ Trueê°’ì„ ë”í•´ì„œ êµ¬í•  ìˆ˜ ìˆë‹¤.

- forë¬¸ì„ í†µí•´ columnë³„ `NaN`ê°’ countê°’ ì¶œë ¥í•˜ê¸°

  ```python
  missing_df = df.isnull()
  for col in missing_df.columns:
      missing_value = missing_df[col].value_counts()
      try:
          print(col, ' :', missing_value[True])
      except:
          print(col, ' :',0)
  ```





### B. NaN ê°’ ì²˜ë¦¬ ë°©ë²•

`NaN` ê°’ì„ ì°¾ì€ ë‹¤ìŒì—ëŠ” `NaN`ì´ ìˆëŠ” í–‰, ì—´ì„ ì‚­ì œí• ê²ƒì¸ì§€, ìœ ì§€í• ê²ƒì¸ì§€ íŒë‹¨í•´ì•¼í•œë‹¤.

ë¶„ì„ì— ìœ ì˜ë¯¸í•œ columnì€ ìµœëŒ€í•œ ìœ ì§€í•´ì•¼í•˜ê³ , ê·¸ ë°˜ëŒ€ëŠ” ì‚­ì œë¥¼ ì„ íƒí•˜ë©´ ëœë‹¤.



ğŸ›¸ **ì‚­ì œ**

ë§Œì•½ ë°ì´í„°ê°€ ì¶©ë¶„íˆ ë§ê³ , ê²°ì¸¡ê°’ì´ ì „ì²´ì˜ 3~4% ì´ë‚´ ì¼ë•Œ, ì‚­ì œë¥¼ í•˜ëŠ” ë°©ë²•ì„ ì‚¬ìš©í•´ ë³¼ ìˆ˜ ìˆë‹¤.

ì‹¬í”Œí•˜ê³ , ë‹¤ë¥¸ ë°ì´í„°ì— ì˜í–¥ì„ ë¼ì¹˜ì§€ë„ ì•Šì§€ë§Œ, ë³´í†µ ë°ì´í„°ë¥¼ í™•ë³´í•˜ëŠ” ê³¼ì •ì—ì„œ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ë‹ˆ ì˜ ì„ íƒí•´ì•¼í•œë‹¤.

- df.drop()

  ```python
  df2 = df.drop('deck', axis=1, inplace=False)
  ```

  `axis` ì†ì„±ì„ ì‚¬ìš©í•´ì„œ í–‰, ì—´ì„ ì‚­ì œí•  ìˆ˜ ìˆë‹¤.

  `inplace` ì†ì„±ì„ ì‚¬ìš©í•´ì„œ ëŒ€ì²´í•  ê²ƒì¸ì§€ ì•„ë‹Œì§€ ì„¤ì •í•  ìˆ˜ ìˆë‹¤.

- thresh ì‚¬ìš©

  ```python
  thresh_df = df.dropna(axis=1, thresh = 500, inplace=False)
  ```

  `thresh`ëŠ” thresholdë¡œ, ì´ ì´ìƒì˜ ê°’ì„ ê°€ì§ˆ ë•Œ ì‚­ì œí•  ìˆ˜ ìˆëŠ” ì†ì„±ì´ë‹¤.

  ìœ„ì˜ì˜ˆì‹œì—ì„œëŠ” ì»¬ëŸ¼ ì¤‘, `NaN`ê°’ì´ 500ê°œ ì´ìƒì¼ ì‹œ ì‚­ì œí•˜ë„ë¡ í•˜ì˜€ë‹¤.

- subsetì— ëŒ€í•´ ê²°ì¹˜ê°’ì´ ìˆëŠ” í–‰ ì‚­ì œ

  ```python
  result_df = df.dropna(subset=['age'], axis=0, how='any')
  ```

  `subset`ì„ ì‚¬ìš©í•´ ì—´ì„ ì •í•´ì£¼ê³ , ê·¸ ì—´ ì¤‘ì—ì„œ `NaN`ê°’ì„ ê°€ì§„ í–‰ì„ ì‚­ì œí•˜ë„ë¡ í•˜ì˜€ë‹¤.

  



ğŸ›¸ **ëŒ€ì²´**

ëŒ€ì²´ì˜ ì¢…ë¥˜ë¡œëŠ” í‰ê· , ì¤‘ìœ„, ìµœëŒ€, ìµœì†Œ, ë¹ˆë„ ë“±ì´ ìˆìœ¼ë©°, ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë²•ìœ¼ë¡œ ê°’ì„ ì˜ˆì¸¡í•´ì„œ ì±„ìš°ëŠ” ë°©ë²•ì´ ìˆë‹¤.

ë°©ë²•ì€ ë¶„ì„í•˜ëŠ” ë°ì´í„°ë¥¼ë³´ê³  ë•Œì— ë§ê²Œ ì‚¬ìš©í•´ì•¼í•œë‹¤.

- í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´

  ```python
  mean_age = df['age'].mean()
  df['age'].fillna(mean_age, inplace=True)
  ```

  'age'ì»¬ëŸ¼ì˜ `NaN`ê°’ì„ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´í•´ì£¼ì—ˆë‹¤.

- ë¹ˆë„ë¥¼ ë³´ê³  ëŒ€ì²´

  ì—¬ëŸ¬ê°€ì§€ ë°ì´í„° ë¶„í¬ë¥¼ ë³´ì•˜ì„ ë•Œ, ë°ì´í„° íŠ¹ì„±ìƒ ì„œë¡œ ì´ì›ƒí•˜ê³  ìˆëŠ” ë°ì´í„°ëŠ” ìœ ì‚¬ì„±ì„ ê°€ì§ˆ í™•ë¥ ì´ ë†’ë‹¤. ì¦‰, ìê¸° ì£¼ë³€ì˜ ë°ì´í„°ì™€ ë¹„ìŠ·í•œ ê²½í–¥ì„ ê°€ì§€ê¸° ë•Œë¬¸ì— `NaN`ê°’ì„ ê·¸ ê°’ìœ¼ë¡œ ëŒ€ì²´í•´ ì¤€ë‹¤.

  ```python
  df['embarked'].fillna(method='ffill', inplace=True)
  # df['embarked'].fillna(method='bfill', inplace=True)
  ```

  `method` ì˜ `'ffill'`ì†ì„±ì€ `NaN`ì˜ Front ê°’ì„ ì‚¬ìš©í•˜ì—¬ ê°’ì„ ì±„ìš°ê² ë‹¤ëŠ” ì†ì„±ì´ë‹¤.
  ë°˜ëŒ€ë¡œ `'bfill'`ì†ì„±ì€ Back ê°’ì„ ì‚¬ìš©í•˜ì—¬ ê°’ì„ ì±„ìš°ê² ë‹¤ëŠ” ì†ì„±ì´ë‹¤.



### 03. Outline

ì´ìƒì¹˜ëŠ” ë°ì´í„°ì—ì„œ ìˆìœ¼ë©´ ì•ˆë˜ëŠ” íŠ€ëŠ” ê°’ì„ ë§í•œë‹¤.

> ì˜ˆì‹œ)
>
> ì‚¬ëŒì˜ í‚¤ëŠ” ë³´í†µ 2ë¯¸í„° ì•„ë˜ì˜ ê°’ì¸ë°, 3ë¯¸í„° ë°ì´í„° ê°’ì€ ì´ìƒì¹˜ë¼ê³  í•  ìˆ˜ ìˆë‹¤.

ê·¸ëŸ¼ ì´ ì´ìƒì¹˜ì˜ ê¸°ì¤€ì„ ì–´ë–»ê²Œ ì •í• ê²ƒì¸ì§€ë¥¼ ì •í•´ì•¼ í•˜ê¸° ë•Œë¬¸ì—, ë°ì´í„°ì— ëŒ€í•œ ë„ë©”ì¸ ì „ë¬¸ê°€ê°€ í•„ìš”í•˜ë‹¤.





### 04. Duplicate

ì¤‘ë³µë˜ëŠ” ê°’ ì¤‘ì—ì„œëŠ” ì˜ë¯¸ê°€ ìˆëŠ” ì¤‘ë³µë„ ìˆê³ , ê·¸ëƒ¥ ì¤‘ë³µëœ ë°ì´í„°ê°€ ì¡´ì¬í•˜ëŠ”ê²ƒì¼ ìˆ˜ë„ ìˆë‹¤.

```python
# duplicate ì˜ˆì‹œ
import numpy as np
import pandas as pd

df = pd.DataFrame({'c1':['a', 'a', 'b', 'a','b'],
                   'c2': [1, 1, 1, 2, 2],
                   'c3': [1, 1, 2, 2, 2]})
```



- duplicated()

  ```python
  df.duplicated()
  ```

- Seriesì—ì„œ duplicate ê°’ ì°¾ê¸°

  ```python
  df['c2'].duplicated()
  ```

- drop_duplicates() - ëª¨ë“  ì»¬ëŸ¼ì„ ë¹„êµ

  ```python
  df.drop_duplicates()
  ```

  drop_duplicates() í•¨ìˆ˜ë¡œ duplicateëœ ê°’ì„ ëª¨ë‘ ì‚­ì œí•  ìˆ˜ ìˆë‹¤.

- drop_duplicates() - íŠ¹ì • ì»¬ëŸ¼ë§Œì„ ë¹„êµ

  ```python
  df.drop_duplicates(subset=['c2','c3'])
  ```

  `subset`ì— ì„¤ì •ëœ columnì—ì„œì˜ duplicateëœ ê°’ì„ ì‚­ì œí•  ìˆ˜ ìˆë‹¤.





### 05. Data Type

Dataë¥¼ Importí•˜ê³  dtypesë¥¼ ë³´ë©´, ë‚´ê°€ ìƒê°í–ˆë˜ê²ƒê³¼ ë‹¤ë¥´ê²Œ ìë£Œí˜•ì´ ë“¤ì–´ê°„ ê²½ìš°ê°€ ìˆë‹¤.

```python
df = pd.read_csv('./data/auto-mpg.csv', header=None)
df.columns = ['mpg', 'cylinders', 'displacement', 'horsepower',
              'weight','acceleration','year','origin','name']
```







#### A. ë°ì´í„° íƒ€ì… ë³€ê²½

#### B. ë²”ì£¼í˜• ë°ì´í„°

ë‚˜ì´ì²˜ëŸ¼ ì—°ì†ì ì¸ ë°ì´í„°ëŠ” ë²”ì£¼í˜• ë°ì´í„°ë¡œ ì²˜ë¦¬í•˜ëŠ”ê²Œ í›¨ì”¬ íš¨ìœ¨ì ì¸ ê²½ìš°ê°€ ìˆë‹¤.

> ì˜ˆì‹œ)
>
> 0~13ì„¸ : ì–´ë¦°ì´
>
> 14~19ì„¸ : ì²­ì†Œë…„
>
> 20~40ì„¸ : ì²­ë…„ 

ì½”ë“œë¡œ êµ¬í˜„í•˜ê¸° ìœ„í•´ êµ¬ê°„ë¶„í•  ì´ë¼ëŠ”ê²ƒì„ ì•Œì•„ì•¼ í•œë‹¤.

ğŸ›¸ **êµ¬ê°„ë¶„í• **

êµ¬ê°„ë¶„í• ì´ë€ ì—°ì†ì ì¸ ë°ì´í„°ë¥¼ ì¼ì •í•œ êµ¬ê°„ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê²ƒì´ë‹¤.

>    \|-------(bin1)---------\|---------(bin2)---------\|----------(bin3)---------\|
>
> ê²½ê³„1                     ê²½ê³„2                          ê²½ê³„3                         ê²½ê³„4
>
> ğŸ‘‰ ê²½ê³„ 4ê°œë¡œ êµ¬ê°„ 3ê°œê°€ ë§Œë“¤ì–´ì§€ëŠ”ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

ì´ë¥¼ ì½”ë“œë¡œ ë§Œë“¤ì–´ë³´ë©´

```python
```

ğŸ›¸ **One-Hot Encoding**

êµ¬ê°„ë¶„í• ì„ í•œ ë°ì´í„°ì˜ ì¹´í…Œê³ ë¦¬ëª…ì€ ìš°ë¦¬ê°€ ì•Œê¸° ì‰¬ìš´ ì–¸ì–´ë¡œ ì˜ êµ¬ë¶„ë˜ì–´ìˆë‹¤.

í•˜ì§€ë§Œ ì´ê²ƒì€ ì‚¬ëŒì´ ë´¤ì„ ë•Œì˜ ì´ì•¼ê¸°ì´ê³ , ì»´í“¨í„°ê°€ ê³„ì‚°í•˜ê¸°ì—ëŠ” ì í•©í•˜ì§€ ì•Šë‹¤.

ê·¸ë˜ì„œ ì»´í“¨í„°ê°€ ì¸ì‹í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë°”ê¾¸ëŠ” ë°©ë²• ì¤‘ í•˜ë‚˜ê°€ One-Hot Encodingì´ë‹¤.

dummy variable(ë”ë¯¸ë³€ìˆ˜) ë¥¼ ì£¼ì–´ í•´ë‹¹ íŠ¹ì„±ì˜ ìœ ë¬´ë¥¼ 0ê³¼ 1ë¡œ í‘œí˜„í•˜ëŠ” ê²ƒì´ë‹¤.

```python
```



### 06. Normalization

ì •ê·œí™”ëŠ” ìˆ«ì ë°ì´í„°ì˜ ìƒëŒ€ì ì¸ ì°¨ì´ë¥¼ ì—†ì• ê¸° ìœ„í•´ í•„ìš”í•˜ë‹¤.

DataFrameì˜ ê° ì—´ì´ ê°€ì§€ê³  ìˆëŠ” ìˆ«ì ë°ì´í„°ì˜ ìƒëŒ€ì ì¸ ì°¨ì´ ë•Œë¬¸ì— ë¨¸ì‹ ëŸ¬ë‹ì˜ ê²°ê³¼ê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆë‹¤.

> ì˜ˆì‹œ)
>
> ë¶€ë™ì‚° ë°ì´í„° ğŸ¡
>
> ì§€ì€ ì—°ìˆ˜ê°€ 1ë…„ì¸ê²ƒê³¼ 40ë…„ì¸ê²ƒ & ê°€ê²©ì´ 1ì–µì¸ê²ƒ, 40ì–µì¸ê²ƒ
>
> ì‚¬ëŒì´ ìƒê°í•˜ê¸°ì—ëŠ” ë‘˜ë‹¤ ì¤‘ìš”í•œ ë³€ìˆ˜ì´ì§€ë§Œ, ì»´í“¨í„°ê°€ ìƒê°í•  ë•Œì—ëŠ” í° ìˆ˜ì—ë” ë¹„ì¤‘ì„ ë‘ê²Œ ë  ìˆ˜ ìˆë‹¤.

ìˆ«ìì˜ ìƒëŒ€ì ì¸ í¬ê¸° ì°¨ì´ë¥¼ ì œê±°í•˜ê¸° ìœ„í•œ ë°©ë²•ì—ëŠ” í‘œì¤€í™”, Min-Max scaling ë“±ì´ ìˆë‹¤.

ğŸ›¸ **í‘œì¤€í™” (Standardization)**

ì •ê·œë¶„í¬ z-score

ğŸ›¸ **Min-Max Scaling**

Min-Max Scaling ê³µì‹
$$
x_{scaled} = {x - x_{min} \over x_{max}-x_{min}}
$$
min-max ê³µì‹ì„ ì‚¬ìš©í•˜ì—¬ ê° ì—´ì„ ì •ê·œí™” í•´ì¤„ ìˆ˜ ìˆë‹¤.

í•˜ì§€ë§Œ min-max scalingì€ ì´ìƒì¹˜ê°€ ì¡´ì¬í•˜ë©´ ì·¨ì•½í•œ ë‹¨ì ì´ ìˆë‹¤.





### 07. ì‹¤ìŠµ

Seabornì—ì„œ ì œê³µí•˜ëŠ” Titanic ë°ì´í„°ì™€ ì´ì „ì‹¤ìŠµì— ì¼ë˜ mpg ë°ì´í„°ë¥¼ ì‹¤ìŠµì— ì‚¬ìš©í•œë‹¤.

PandasëŠ” ê·¸ë˜í”„ë„êµ¬ë¥¼ ë‚´ì¥í•˜ê³  ìˆëŠ”ë°, ì´ ê¸°ëŠ¥ë“¤ì€ matplotlibìœ¼ë¡œë¶€í„° ì°¨ìš©ëœ ê²ƒì´ë‹¤.

ê·¸ë˜ì„œ Pandasì˜ ê·¸ë˜í”„ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒ ë³´ë‹¤ matplotlib ì‚¬ìš©ë²•ì„ ë°°ì›Œë³´ëŠ”ê²ƒì´ ì¢‹ë‹¤.

```python
# Seaborn ë‹¤ìš´ë¡œë“œ
> conda install seaborn
```

```python
#Seaborn ì„ ì–¸
import seaborn as sns
```

Seabornë„ ë‹¤ë¥¸ moduleì²˜ëŸ¼ ìì£¼ì“°ëŠ” ì•½ì–´ê°€ ìˆë‹¤.



#### A. Data Loading

```python
import numpy as np
import pandas as pd
import seaborn as sns

# titanic data set loading
df = sns.load_dataset('titanic')
```











